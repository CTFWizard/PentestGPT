# an automated penetration testing parser empowered by GPT
from rich.spinner import Spinner
from pentestgpt.utils.APIs.module_import import dynamic_import
from pentestgpt.prompts.prompt_class import PentestGPTPrompt
from pentestgpt.utils.prompt_select import prompt_ask
from prompt_toolkit.formatted_text import HTML
from prompt_toolkit.shortcuts import confirm
from pentestgpt.utils.task_handler import (
    main_task_entry,
    mainTaskCompleter,
    local_task_entry,
    localTaskCompleter,
)
from pentestgpt.utils.web_parser import google_search
from pentestgpt.code.parsing import ParsingModule
from pentestgpt.code.generation import GenerationModule
from pentestgpt.code.reasoning import ReasoningModule

from pentestgpt.utils.console import console

import loguru
import time, os, textwrap, json, sys, traceback

logger = loguru.logger #TODO: Fix logging? or just let be


class PentestGPT:
    """A class to control logic flow

    ...
    Attributes
    ----------
    log_dir : str
        Directory for log storage
    reasoning_model : str
        LLM for the reasoning module
    parsing_model : str
        LLM for the parsing module
    use_langfuse_logging : bool, optional
        Enable langchain logging (default is False)
    """
    def __init__(
        self,
        log_dir="logs",
        reasoning_model="gpt-4-1106-preview",
        parsing_model="gpt-4-1106-preview",
        use_langfuse_logging=False,
    ): # TODO: Remove depreceated api paramter
        self.log_dir = log_dir
        logger.add(sink=os.path.join(log_dir, "pentestGPT.log"))
        self.save_dir = "test_history"
        self.task_log = (
            {}
        )  # the information that can be saved to continue in the next session
        self.parsing_char_window = 16000  # the chunk size for parsing in # of chars
        # TODO: link the parsing_char_window to the model used
        # load the module
        reasoning_model_object = dynamic_import(
            reasoning_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )
        generation_model_object = dynamic_import(
            reasoning_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )
        parsing_model_object = dynamic_import(
            parsing_model, self.log_dir, use_langfuse_logging=use_langfuse_logging
        )
        self.parsingAgent = ParsingModule(parsing_model_object)
        self.generationAgent = GenerationModule(generation_model_object)
        self.reasoningAgent = ReasoningModule(reasoning_model_object)
        self.prompts = PentestGPTPrompt
        self.console = console
        self.spinner = Spinner("line", "Processing")
        self.test_generation_session_id = None
        self.test_reasoning_session_id = None
        self.input_parsing_session_id = None
        self.step_reasoning = (
            None  # the response from the reasoning session for the current step
        )
        self.history = {
            "user": [],
            "pentestGPT": [],
            "reasoning": [],
            "input_parsing": [],
            "generation": [],
            "exception": [],
        }  # the history of the current conversation

        # print the initialization message on the current implementation.
        self.console.print(
            "Welcome to pentestGPT, an automated penetration testing parser empowered by GPT.",
            style="bold green",
        )
        self.console.print("The settings are: ")
        self.console.print(
            f" - parsing model: {parsing_model_object.name}", style="bold green"
        )
        self.console.print(
            f" - reasoning model: {reasoning_model_object.name}", style="bold green"
        )
        self.console.print(f" - log directory: {log_dir}", style="bold green")

    def log_conversation(self, source, text):
        """
        append the conversation into the history

        Parameters:
        ----------
        source: str
            the source of the conversation
        text: str
            the content of the conversation
        """
        # append the conversation into the history
        timestamp = time.time()
        if source not in self.history.keys():
            # an exception
            source = "exception"
        self.history[source].append((timestamp, text))

    def _feed_init_prompts(self):
        # 1. User firstly provide basic information of the task
        init_description = prompt_ask(
            "Please describe the penetration testing task in one line, including the target IP, task type, etc.\n> ",
            multiline=False,
        )
        self.log_conversation("user", init_description)
        self.task_log["task description"] = init_description
        # 2. Provide the information to the reasoning session for the task initialization.
        # Note that this information is not parsed by the three-step process in reasoning.
        # It is directly used to initialize the task.
        prefixed_init_description = self.prompts.task_description + init_description
        with self.console.status(
            "[bold green] Constructing Initial Penetration Testing Tree..."
        ) as status:
            _reasoning_response = self.reasoningAgent.reasoning_model.send_message(
                prefixed_init_description, self.test_reasoning_session_id
            )
        # 3. Pass to generation session for more details.
        # Note that the generation session is not used for the task initialization.
        with self.console.status("[bold green] Generating Initial Task") as status:
            _generation_response = self.generationAgent.generation_model.send_message(
                self.prompts.todo_to_command + _reasoning_response,
                self.test_generation_session_id,
            )

        # Display the initial generation result
        response = _reasoning_response + "\n" + _generation_response
        self.console.print("PentestGPT output: ", style="bold green")
        self.console.print(response)
        self.log_conversation("PentestGPT", "PentestGPT output:" + response)

    def initialize(self, previous_session_ids=None):
        # initialize the backbone sessions and test the connection to chatGPT
        # define three sessions: testGenerationSession, testReasoningSession, and InputParsingSession
        with self.console.status(
            "[bold green] Initialize ChatGPT Sessions..."
        ) as status:
            try:
                (
                    text_0,
                    self.test_generation_session_id,
                ) = self.generationAgent.generation_model.send_new_message(
                    self.prompts.generation_session_init,
                )
                (
                    text_1,
                    self.test_reasoning_session_id,
                ) = self.reasoningAgent.reasoning_model.send_new_message(
                    self.prompts.reasoning_session_init
                )
                (
                    text_2,
                    self.input_parsing_session_id,
                ) = self.parsingAgent.parsing_model.send_new_message(
                    self.prompts.input_parsing_init
                )
            except Exception as e:
                logger.error(e)
            self.console.print("- ChatGPT Sessions Initialized.", style="bold green")
            self._feed_init_prompts()

    def save_session(self): 
        """
        Save the current session for next round of usage.
        The test information is saved in the directory `./test_history`
        """
        self.console.print(
            "Before you quit, you may want to save the current session.",
            style="bold green",
        )
        # 1. Require a save name from the user. If not, use the current time as the save name.
        save_name = prompt_ask(
            "Please enter the name of the current session. (Default with current timestamp)\n> ",
            multiline=False,
        )
        if save_name == "":
            save_name = str(time.time())
        # 2. Save the current session
        with open(
            os.path.join(
                os.path.realpath(os.path.dirname(__file__)),
                os.pardir,
                os.pardir,
                self.save_dir,
                save_name,
            ),
            "w",
        ) as f:
            # store the three ids and task_log
            session_ids = {
                "reasoning": self.test_reasoning_session_id,
                "test_generation": self.test_generation_session_id,
                "parsing": self.input_parsing_session_id,
                "task_log": self.task_log,
            }
            json.dump(session_ids, f)
        self.console.print(
            f"The current session is saved as {save_name}", style="bold green"
        )
        return

    def _preload_session(self) -> dict:
        """
        Preload the session from the save directory.

        Returns:
            dict: the session ids for the three sessions.
            None if no previous session is found.
        """
        if continue_from_previous := confirm(
            "Do you want to continue from previous session?"
        ):
            # load the filenames from the save directory
            filenames = os.listdir(
                os.path.join(
                    os.path.realpath(os.path.dirname(__file__)),
                    os.pardir,
                    os.pardir,
                    self.save_dir,
                )
            )
            if len(filenames) == 0:
                print("No previous session found. Please start a new session.")
                return None
            else:  # print all the files
                print("Please select the previous session by its index (integer):")
                for i, filename in enumerate(filenames):
                    print(f"{str(i)}. {filename}")
                # ask for the user input
                try:
                    previous_testing_name = filenames[
                        int(input("Please key in your option (integer): "))
                    ]
                    print(f"You selected: {previous_testing_name}")
                except ValueError as e:
                    print("You input an invalid option. Will start a new session.")
                    return None

        elif continue_from_previous is False:
            return None
        else:
            print("You input an invalid option. Will start a new session.")
            return None
        # 2. load the previous session information
        if previous_testing_name is not None:
            # try to load the file content with json
            try:
                with open(
                    os.path.join(
                        os.path.realpath(os.path.dirname(__file__)),
                        os.pardir,
                        os.pardir,
                        self.save_dir,
                        previous_testing_name,
                    ),
                    "r",
                ) as f:
                    return json.load(f)
            except Exception as e:
                print(
                    "Error when loading the previous session. The file name is not correct"
                )
                print(e)
                previous_testing_name = None
                return None

    def input_handler(self):
        """
        Request for user's input to:
            (1) input test results,
            (2) ask for todos,
            (3) input other information (discuss),
            (4) google.
            (4) end.
        The design details are based on PentestGPT_design.md

        Return
        -----
        response: str
            The response from the chatGPT model.
        """
        llm_response = ""

        request_option = main_task_entry()
        if request_option == "help":
                print(mainTaskCompleter().task_details)

        if request_option == "next":
            # (2) Pass summarization to the reasoning session
            reasoning_response = self.reasoningAgent.next_task()
            # Set the current reasoning response
            self.step_reasoning_response = reasoning_response

        if request_option == "more":
            ## (1) check if reasoning session is initialized
            if not hasattr(self, "step_reasoning_response"):
                self.console.print(
                    "You have not initialized the task yet. Please perform the basic testing following `next` option.",
                    style="bold red",
                )
                response = "You have not initialized the task yet. Please perform the basic testing following `next` option."
                self.log_conversation("pentestGPT", response)
                return response
            self.console.print(
                "PentestGPT will generate more test details, and enter the sub-task generation mode. (Pressing Enter to continue)",
                style="bold green",
            )
            self.log_conversation(
                "pentestGPT",
                "PentestGPT will generate more test details, and enter the sub-task generation mode.",
            )
            input() # Press enter to continue
            self.generationAgent.more(self.step_reasoning_response)

        if request_option == "todo":
            ## log that user is asking for todo list
            self.log_conversation("user", "todo")
            ## (1) ask the reasoning session to analyze the current situation, and list the top sub-tasks
            with self.console.status("[bold green] PentestGPT Thinking...") as status:
                reasoning_response = self.reasoningAgent.reasoning_handler(self.prompts.ask_todo)
                ## (2) pass the sub-tasks to the test_generation session.
                message = self.prompts.todo_to_command + "\n" + reasoning_response
                generation_response = self.generationAgent.test_generation_handler(message)
                ## (3) print the results
            self.console.print(
                "Based on the analysis, the following tasks are recommended:",
                style="bold green",
            )
            self.console.print(reasoning_response + "\n")
            self.console.print(
                "You can follow the instructions below to complete the tasks.",
                style="bold green",
            )
            self.console.print(generation_response + "\n")
            response = reasoning_response
            self.log_conversation(
                "pentestGPT",
                (
                    (
                        (
                            (
                                "Based on the analysis, the following tasks are recommended:"
                                + response
                            )
                            + "\n"
                        )
                        + "You can follow the instructions below to complete the tasks."
                    )
                    + generation_response
                ),
            )
        if request_option == "google":
            # get the users input
            self.console.print(
                "Please enter your search query. PentestGPT will summarize the info from google. (End with <shift + right-arrow>) ",
                style="bold green",
            )
            self.log_conversation(
                "pentestGPT",
                "Please enter your search query. PentestGPT will summarize the info from google.",
            )
            user_input = prompt_ask("Your input: ", multiline=False)
            self.log_conversation("user", user_input)
            with self.console.status("[bold green] PentestGPT Thinking...") as status:
                # query the question
                result: dict = google_search(user_input, 5)  # 5 results by default
                # summarize the results
                # TODO
                response = "Google search results:\n" + "still under development."
            self.console.print(response + "\n", style="yellow")
            self.log_conversation("pentestGPT", response)
            return response
        if request_option == "discuss":
            ## (1) Request for user multi-line input
            self.console.print(
                "Please share your thoughts/questions with PentestGPT. (End with <shift + right-arrow>) "
            )
            self.log_conversation(
                "pentestGPT", "Please share your thoughts/questions with PentestGPT."
            )
            user_input = prompt_ask("Your input: ", multiline=True)
            self.log_conversation("user", user_input)
            ## (2) pass the information to the reasoning session.
            with self.console.status("[bold green] PentestGPT Thinking...") as status:
                response = self.reasoningAgent.reasoning_handler(self.prompts.discussion + user_input)
            ## (3) print the results
            self.console.print("PentestGPT:\n", style="bold green")
            self.console.print(response + "\n", style="yellow")
            self.log_conversation("pentestGPT", response)

        elif request_option == "quit":
            response = False
            self.console.print("Thank you for using PentestGPT!", style="bold green")
            self.log_conversation("pentestGPT", "Thank you for using PentestGPT!")

        else:
            self.console.print("Please key in the correct options.", style="bold red")
            self.log_conversation("pentestGPT", "Please key in the correct options.")
            response = "Please key in the correct options."
        return llm_response



    def main(self):
        """
        The main function of pentestGPT. The design is based on PentestGPT_design.md
        """
        # 0. initialize the backbone sessions and test the connection to chatGPT
        loaded_ids = self._preload_session()
        self.initialize(previous_session_ids=loaded_ids)

        # enter the main loop.
        while True:
            try:
                result = self.input_handler()
                self.console.print(
                    "-----------------------------------------", style="bold white"
                )
                if not result:  # end the session
                    break
            except Exception as e:  # catch all general exception.
                # log the exception
                self.log_conversation("exception", str(e))
                # print the exception
                self.console.print(f"Exception: {str(e)}", style="bold red")
                # add a more detailed debugging
                exc_type, exc_obj, exc_tb = sys.exc_info()
                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
                self.console.print(
                    "Exception details are below. You may submit an issue on github and paste the error trace",
                    style="bold green",
                )
                # self.console.print(exc_type, fname, exc_tb.tb_lineno)
                print(traceback.format_exc())
                # safely quit the session
                break
        # log the session. Save self.history into a txt file based on timestamp
        timestamp = time.time()
        log_name = f"pentestGPT_log_{str(timestamp)}.txt"
        # save it in the logs folder
        log_path = os.path.join(self.log_dir, log_name)
        with open(log_path, "w") as f:
            json.dump(self.history, f)

        # save the sessions; continue from previous testing
        self.save_session()


if __name__ == "__main__":
    pentestGPT = PentestGPT()
    pentestGPT.main()
